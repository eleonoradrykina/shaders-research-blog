[["Map",1,2,7,8],"meta::meta",["Map",3,4,5,6],"astro-version","5.0.3","config-digest","8d1b7566f4d3c391","blog",["Map",9,10,20,21,30,31,40,41,50,51,60,61],"01-06-start",{"id":9,"data":11,"body":16,"filePath":17,"digest":18,"deferredRender":19},{"title":12,"description":13,"pubDate":14,"heroImage":15},"Starting with resources","What we going to read and watch",["Date","2025-01-05T23:00:00.000Z"],"blog-placeholder-3.jpg","import Takeaway from \"../../components/Takeaway.astro\";\n\nFirst things first: before starting this project, I have several links and tabs hanging open in my Google for weeks.\nToday I sorted them into more or less subtopics of my research resources:\n\n| SHADING LANGUAGES    | Links |\n| -------- | ------- |\n| TSL  | [Specification](https://github.com/mrdoob/three.js/wiki/Three.js-Shading-Language)   |\n| TSL | [Medium Article and video from @gianluca.lomarco](https://medium.com/@gianluca.lomarco/three-js-shading-language-a-new-era-for-shaders-cd48de8b22b0)   |\n| WGSL    | [Damien Seguin: comparing WGSL and GLSL](https://dmnsgn.me/blog/from-glsl-to-wgsl-the-future-of-shaders-on-the-web/)   |\n| WGSL    | [WebGPU best Practices pdf from Khronos Group](https://www.khronos.org/assets/uploads/developers/presentations/WebGPU_Best_Practices_Google.pdf)|\n| WGSL    | [Podcast with Gregg Tavares (author of WebGL/WebGPU Fundamentals)](https://changelog.com/jsparty/304)|\n| GLSL    | [All shaders lessons of Bruno Simon](https://threejs-journey.com/lessons/shader-patterns) |\n| GLSL    | [Non-Figurativ \"Entanglement\" piece source code](https://github.com/bgstaal/gpuparticles)|\n\n**Extra:** \n[Introduction to Signed Distance Fields](https://www.youtube.com/watch?v=pEdlZ9W2Xs0)\n\n\n| More on WebGPU   | Links |\n| -------- | ------- |\n| WebGPU Fundamentals    | [Github Repo](https://github.com/webgpu/webgpufundamentals) |\n| WebGPU Fundamentals    | [Webgpufundamentals.org Lessons](https://webgpufundamentals.org/webgpu/lessons/webgpu-wgsl.html)|\n| WebGL & WebGPU Meetup - November 2024  | [Youtube video](https://www.youtube.com/watch?v=koY-kDb50VI) |\n\n| Working with Shaders and Materials | Links |\n| -------- | ------- |\n| Nodetoy   | https://nodetoy.co/|\n| Material X    | https://materialx.org/ |\n\n\nI started with reading Medium Article and watching Youtube video from @gianluca.lomarco about what Threejs Shading Language is (finally italian skills come in use!).\nTo plan what I am going to do, I wanted to get a better understanding of what **TSL** is.\nMain takeaways are:\n\u003CTakeaway header=\"Nodes\">\nTSL facilitates shader development by breaking down the shaders into a series of nodes, each applying a specific effect. These nodes can be combined to generate the final shader.\n\u003C/Takeaway>\n\n\u003CTakeaway header=\"WEBGL & WEBGPU\">\nTSL will automatically handle the adaptation for the appropriate API, whether GLSL for WebGL or WGSL for WebGPU.\n\u003C/Takeaway>\n\nNext steps for me will be to get more comofrtable with writing shading langugaes and plan out the roadmap.","src/content/blog/01-06-start.mdx","7619c5767a952c82",true,"01-07-writing-shaders",{"id":20,"data":22,"body":27,"filePath":28,"digest":29,"deferredRender":19},{"title":23,"description":24,"pubDate":25,"heroImage":26},"GLSL tutorials","Remembering how to write shaders",["Date","2025-01-06T23:00:00.000Z"],"shader-1.png","I started with Bruno Simon's tutorials to remember basics of GLSL, and already found out interesting combinations:\n``` javascript\n   //BLINGS MEETING EACH OTHER\n    vec2 rotatedUv = rotate(vUV, PI/4.0, vec2(0.5, 0.5));\n\n    vec2 lightUv = vec2(\n        rotatedUv.x*0.2 + 0.45,\n        rotatedUv.y \n    );\n\n    float strengthX = 0.125 / distance(lightUv, vec2(0.5, 0.5));\n\n    vec2 lightUv2 = vec2(\n        rotatedUv.x,\n        rotatedUv.y*0.01 + 0.35\n    );\n\n     float strengthY = 0.125 / distance(lightUv2, vec2(0.5, 0.5));\n     float strength = strengthX * strengthY;\n\n     //CLAMP STRNGTH\n    strength = clamp (strength, 0.0, 1.0);\n\n    //COLORED\n    vec3 firstColor = vec3(0.0345, 0.07, 0.11);\n    vec3 secondColor = vec3(vUV, 1.0);\n\n    vec3 color = mix(firstColor, secondColor, strength);\n\n\n    gl_FragColor = vec4(vec3(color), 1.0);\n    ```\n\n    This produces gradients that look like light flare like at the cover of this post.","src/content/blog/01-07-writing-shaders.mdx","f9e144d10fd9d0a3","01-08-first-wgsl-shader",{"id":30,"data":32,"body":37,"filePath":38,"digest":39,"deferredRender":19},{"title":33,"description":34,"pubDate":35,"heroImage":36},"My first WGSL shader","Understanding WGSL semantics",["Date","2025-01-07T23:00:00.000Z"],"shader-2.png","#### Meeting\n\nToday started with the first coach meeting. Wouter suggested to start with [WebGPU Fundamentals](https://webgpufundamentals.org/webgpu/lessons/webgpu-how-it-works.html#toc), where I accidentally opened a lesson from the middle instead of the beginning.\n\n#### WebGPU Fundamentals && Tour of WGSL\nSeeing snippets of WGSL code I was quite lost, but then I saw [Tour of WGSL](https://google.github.io/tour-of-wgsl/).\nTo understand the context better, I have decided to try out WGSL directly, so I went through the half of the tour and saved some memroy anchors to my figma conspect:\n![WGSL Figma concept](/shaders-research-blog/images/conspect.png)\n\nTo get more comfortable with WGSL, I decided to use a turn a little example from **Book of Shaders into WGSL:**\n```javascript\n@binding(0) @group(0) var\u003Cuniform> frame : u32;\n\n@vertex\nfn vtx_main(@builtin(vertex_index) vertex_index : u32) -> @builtin(position) vec4f {\n  const pos = array(\n    vec2( 0.0,  1.0),\n    vec2( -1.0, -1.0),\n    vec2( 1.0, -1.0),\n  );\n\n  return vec4f(pos[vertex_index], 0, 1);\n}\n//https://thebookofshaders.com/08/\n// YUV to RGB matrix\nconst yuv2rgb = mat3x3f(1.0, 0.0, 1.13983,\n                    1.0, -0.39465, -0.58060,\n                    1.0, 2.03211, 0.0);\n\n@fragment\nfn frag_main() -> @location(0) vec4f {\n  var color : vec3f = yuv2rgb * vec3f(0.5, sin(f32(frame) / 128), 0.5);\n  return vec4(color, 1);\n}\n```\n\n**Multiplying colors by YUV matrix** turned from yellowish-greenish triangle into cyan, although it's not quite clear on the hero Image of the post, we all need to start somewhere=).\nOn my way there I also got a bit distracted with a [reminder how multiplying matrices works](https://mathinsight.org/matrix_vector_multiplication#:~:text=Matrix%2Dvector%20product&text=If%20we%20let%20Ax,na21a22%E2%80%A6), I had a vague memory from high school but wanted to understand the outcome better.\n\nThen I re-read Fundamentals articles again and I feel how it starts to layer in my head.\n\n#### Three.js Shading Language\n\nWhile trying to understand how WebGPU works, I wanted to make sure to understand the **difference between WGSL and TSL.** After scanning documentation and examples, I wasn't quite sure I understood it correctly. \nThe examples on three js website do contain TSL already used with WebGPU, but not shaders written in WGSl. Lately when I need to summarise new things I learned I ask ChatGpt to explain me concepts as an example of pizzeria:\n![TSL-pizza](/shaders-research-blog/images/TSL-pizza.png)\n\n\n#### Planning\nFor tomorrow I am planning to:\n- map out the roadmap;\n- start from [proper beginning of WebGPU Fundamentals](https://webgpufundamentals.org/webgpu/lessons/webgpu-fundamentals.html) again;\n- re-visit [this article about differences between WebGL and WebGPU](https://webgpufundamentals.org/webgpu/lessons/webgpu-from-webgl.html), as it brings more clarity to me:\n![conspect-3](/shaders-research-blog/images/conspect-3.png)\nI also saved this comparison\n![conspect-2](/shaders-research-blog/images/conspect-2.png)\n\nBy the way, I just learned that actually its best practice **not to use ternary opeartors, or any flow controls,** when writing GLSL code as it's not good for performance, it might apply to WGSL as well.\n\n\n*My research might seem not linear right now, but I need to get the gist of the context and try out things to better understand the basics.*","src/content/blog/01-08-first-wgsl-shader.mdx","7e3330e00d2b632b","01-09-roadmap",{"id":40,"data":42,"body":47,"filePath":48,"digest":49,"deferredRender":19},{"title":43,"description":44,"pubDate":45,"heroImage":46},"Timeline","Timeplanning",["Date","2025-01-08T23:00:00.000Z"],"timeline.png","import Takeaway from \"../../components/Takeaway.astro\";\n\n#### Roadmap\n\nI tried to come up with a roadmap for my research, but for now I was able only to have very rough timeline:\n![timeline](/shaders-research-blog/images/timeline.png)\n\nI think of my features more of like happy accidents during research, but I will plan them more precisely this week for sure.\nMeanwhile, I also went back to the very beginning of WebGPU Fundamentals.\n\n#### WebGPU Fundamentals\n\nThe first thing that caught my eye was that **WebGPU is an asynchronous API** and is used inside of an **async function**.\nAnother thing was **requesting an adaper**:\n```javascript\nasync function main() {\n  const adapter = await navigator.gpu?.requestAdapter();\n  const device = await adapter?.requestDevice();\n  if (!device) {\n    fail('need a browser that supports WebGPU');\n    return;\n  }\n}\nmain();\n```\nThe adapter represents a specific GPU. Some devices have multiple GPUs.\n\nOkay, now an important takeaway:\n\u003CTakeaway>\n\"Shaders are written in a language called WebGPU Shading Language (WGSL) which is often pronounced wig-sil.\"\nI need to train it more: ***WIG-SIL***\n\u003C/Takeaway>\n\nBy the time I got to a red triangle on canvas, I had this conspect in Figma:\n\n![conspect](/shaders-research-blog/images/WebGPU-setup.png)\n\nNow it makes more sense, so we can move further to **running computations on the GPU.**","src/content/blog/01-09-roadmap.mdx","589fd2ba10444241","01-13-textures",{"id":50,"data":52,"body":57,"filePath":58,"digest":59,"deferredRender":19},{"title":53,"description":54,"pubDate":55,"heroImage":56},"Textures in WebGPU","Slowly goiing further",["Date","2025-01-12T23:00:00.000Z"],"vert-frag.png","import Takeaway from \"../../components/Takeaway.astro\";\n\n#### Vertex and Storage buffers\nBefore going further to textures, I've went through storage & vertex buffers lessons.\nBuffer data is a new concept for me to use in coding, but it's one of essentials used in WGSL if you want to go further than triangles.\n\nI already used **Uniform Buffers** in previous lesson, now we're looking into **Storage** and **Vertex** buffers.\n\nOne of the main differences of Vertex buffer is how shaders access it. We need to explain to WebGPU what it is and how it's organized:\n\n![tell WebGPU how to supply data ](/shaders-research-blog/images/vertex-data-supply.png)\n\nTo the vertex entry of the pipeline descriptor we added a buffers array which is used to describe how to pull data out of 1 or more vertex buffers. For our first and only buffer, we set an arrayStride in number of bytes. A stride in this case is how many bytes to get from the data for one vertex in the buffer, to the next vertex in the buffer.\n\nAfter several examples I also understood how to use the stride offset when passing attributes to shader:\n```javascript\nbuffers: [\n                {\n                    arrayStride: 5 * 4, // 2 floats, 4 bytes each\n                    attributes: [\n                        { shaderLocation: 0, offset: 0, format: 'float32x2' },  // position\n                        { shaderLocation: 4, offset: 8, format: 'float32x3' },  // perVertexColor\n                    ],\n                },\n                ...\n]\n```\n![stride](/shaders-research-blog/images/stride.png)\n#### Index buffers\nFor optimizing vertices computaion, we can use index buffers to re-use existing vertices:\n![index buffers](/shaders-research-blog/images/index-buffers.png)\n\nThen the code turns into this, creating vertices and also **Index Data**:\n```javascript\nfunction createCircleVertices({\n    radius = 1,\n    numSubdivisions = 24,\n    innerRadius = 0,\n    startAngle = 0,\n    endAngle = Math.PI * 2,\n} = {}) {\n    // 2 vertices at each subdivision, + 1 to wrap around the circle.\n    const numVertices = (numSubdivisions + 1) * 2;\n    // const vertexData = new Float32Array(numSubdivisions * 2 * 3 * 2);\n    const vertexData = new Float32Array(numVertices * (2 + 3));\n\n    let offset = 0;\n    const addVertex = (x, y, r, g, b) => {\n        vertexData[offset++] = x;\n        vertexData[offset++] = y;\n        vertexData[offset++] = r;\n        vertexData[offset++] = g;\n        vertexData[offset++] = b;\n    };\n\n    const innerColor = [0.3, 0.3, 0.9];\n    const outerColor = [0.9, 0.9, 0.9];\n\n    // 2 triangles per subdivision\n    //\n    // 0  2  4  6  8 ...\n    //\n    // 1  3  5  7  9 ...\n    for (let i = 0; i \u003C= numSubdivisions; ++i) {\n        const angle = startAngle + (i + 0) * (endAngle - startAngle) / numSubdivisions;\n\n        const c1 = Math.cos(angle);\n        const s1 = Math.sin(angle);\n\n        addVertex(c1 * radius, s1 * radius, ...outerColor);\n        addVertex(c1 * innerRadius, s1 * innerRadius, ...innerColor);\n    }\n\n    const indexData = new Uint32Array(numSubdivisions * 6);\n    let ndx = 0;\n\n    // 1st tri  2nd tri  3rd tri  4th tri\n    // 0 1 2    2 1 3    2 3 4    4 3 5\n    //\n    // 0--2        2     2--4        4  .....\n    // | /        /|     | /        /|\n    // |/        / |     |/        / |\n    // 1        1--3     3        3--5  .....\n    for (let i = 0; i \u003C numSubdivisions; ++i) {\n        const ndxOffset = i * 2;\n\n        // first triangle\n        indexData[ndx++] = ndxOffset;\n        indexData[ndx++] = ndxOffset + 1;\n        indexData[ndx++] = ndxOffset + 2;\n\n        // second triangle\n        indexData[ndx++] = ndxOffset + 2;\n        indexData[ndx++] = ndxOffset + 1;\n        indexData[ndx++] = ndxOffset + 3;\n    }\n\n    return {\n        vertexData,\n        indexData,\n        numVertices: indexData.length,\n    };\n}\n```\nWe then set Index Buffer as well to pass our index data.\nWe also need to call different draw function:\n```javascript\n        pass.drawIndexed(numVertices, kNumObjects);\n```\nAnd we **saved 33% vertices**, slay!\nThis is what's we're getting by the way:\n![indexBuffer](/shaders-research-blog/images/indexBuffer.png)\n\nNow we're ready to go to **textures**.\n\n#### Textures\n\nOkay, we're finally at the last part of passing data into the WebGPU shaders!\n\nThe major difference for textures is that they are accessed by **sampler**, which can blend up to 16 values together in a texture.\nAs if there was not enough new information before yay....\n\nThe first thing I noticed when started following the lesson is **flipped textures,** which we faced a lot during Bachelor Thesis, and here was the eplanation for that:\n\n![indexBuffer](/shaders-research-blog/images/flipped-textures.png)\n\nIt was also nice finally to see familiar things about UV explanation and mixing, this is something I've encountered before and is easier for comprehension=)\nI think I finally understood meaning of **magFilter** and clamping textures to edge / repeating, which I saw in three js before very briefly:\n![magFilter](/shaders-research-blog/images/magFilter.png)\n\nIt's nice knowing that even if I am not writing shaders low-level daily, I understand how graphics api works in general better!","src/content/blog/01-13-textures.mdx","9a40c9e6a9375931","01-10-computing-shaders",{"id":60,"data":62,"body":66,"filePath":67,"digest":68,"deferredRender":19},{"title":63,"description":64,"pubDate":65,"heroImage":56},"Computing shaders","Continiuing with WGSL",["Date","2025-01-09T23:00:00.000Z"],"import Takeaway from \"../../components/Takeaway.astro\";\n\n#### Computing Shaders\nToday I started with WebGPU Fundamentals again, going further to Computing shaders.\n\nThe first thing that is different from yesterdays **fragment** and **vertex** shaders is that we need **storage variable**:\n```javascript\n      @group(0) @binding(0) var\u003Cstorage, read_write> data: array\u003Cf32>;\n```\nThe thing that still confuses me a bit is *locations* in WGSL shaders:\n\"We tell it we’re going to specify this array on binding location 0 (the binding(0)) in bindGroup 0 (the @group(0)).\"\n\nThings get more interesting when we need to create separate buffers to **store** the data in and to **read** the data from:\n```javascript\n  //data for compute shader\n  const input = new Float32Array([1, 3, 5]);\n\n  //For WebGPU to use it, we need to make a buffer that exists on the GPU and copy the data to the buffer.\n\n  // create a buffer on the GPU to hold our computation\n  // input and output\n  const workBuffer = device.createBuffer({\n    label: 'work buffer',\n    size: input.byteLength,\n    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST,\n  });\n  // Copy our input data to that buffer\n  device.queue.writeBuffer(workBuffer, 0, input);\n\n  // create a buffer on the GPU to get a copy of the results\n  const resultBuffer = device.createBuffer({\n    label: 'result buffer',\n    size: input.byteLength,\n    usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST\n  });\n\n  // Setup a bindGroup to tell the shader which\n  // buffer to use for the computation\n  const bindGroup = device.createBindGroup({\n    label: 'bindGroup for work buffer',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: workBuffer } },\n    ],\n  });\n  ```\n\n  #### WebGPU Inter-stage Variables\n\n  Moving on to WebGPU Inter-stage Variables, in next chapter I learned how to pass structures (of which I think kind of like js classes) between 2 shaders:\n\n  ```javascript\n        struct OurVertexShaderOutput {\n        @builtin(position) position: vec4f,\n        @location(0) color: vec4f,\n      };\n      @vertex fn vs(\n        @builtin(vertex_index) vertexIndex : u32\n     ) -> OurVertexShaderOutput {\n        let pos = array(\n          vec2f( 0.0,  0.5),  // top center\n          vec2f(-0.5, -0.5),  // bottom left\n          vec2f( 0.5, -0.5)   // bottom right\n        );\n\n        let color = array(\n          vec4f(1, 0, 0, 1), // red\n          vec4f(0, 1, 0, 1), // green\n          vec4f(0, 0, 1, 1), // blue\n        );\n \n        var vsOutput: OurVertexShaderOutput;\n        vsOutput.position = vec4f(pos[vertexIndex], 0.0, 1.0);\n        vsOutput.color = color[vertexIndex];\n        return vsOutput;\n      }\n \n       @fragment fn fs(fsInput: OurVertexShaderOutput) -> @location(0) vec4f {\n        let red = vec4f(1, 0, 0, 1);\n        let colored = fsInput.color;\n\n        let grid = vec2u(fsInput.position.xy) / 16;\n        let checker = (grid.x + grid.y) % 2 == 1;\n\n        return select(red, colored, checker);\n      }\n  ```\nHere I combined 2 examples to both **pass color from vertex shader to frag shader**, and to add **condition** to use the **passed color or red** in frag shader.\nThis is the outcome:\n![vertex-to-frag](/shaders-research-blog/images/vert-frag.png)\n\n#### Uniforms\nUniforms look just like in GLSL with some differences:\nto create a Uniform, first we need to descripe its' \"class\" aka struct:\n\n```javascript\n    struct OurStruct {\n        color: vec4f,\n        scale: vec2f,\n        offset: vec2f,\n      };\n```\n\nThen, we need to declare a uniform with type of our struct:\n\n```javascript\n@group(0) @binding(0) var\u003Cuniform> ourStruct: OurStruct;\n```\nand after this we can use uniforms in our shader code.\nTo be able to se the from Javascript, we also need to create a buffer first, and to calculate it's size:\n```javascript  \nconst uniformBufferSize =\n    4 * 4 + // color is 4 32bit floats (4bytes each)\n    2 * 4 + // scale is 2 32bit floats (4bytes each)\n    2 * 4;  // offset is 2 32bit floats (4bytes each)\n  const uniformBuffer = device.createBuffer({\n    label: 'uniforms for triangle',\n    size: uniformBufferSize,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n  ```\n  after playing with setting uniforms a bit, I got this beautiful rotating triangle:\n\n![rotating-trinagle](/shaders-research-blog/images/wgsl-uniforms.gif)","src/content/blog/01-10-computing-shaders.mdx","78a51b5f49614566"]